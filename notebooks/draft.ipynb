{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75adc9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'202505161637': ('AUC', 1.0, 1e-05, datetime.datetime(2025, 5, 16, 18, 54, 18, 622859)), '202505070419': ('Precision', 1.0, 1e-05, datetime.datetime(2025, 5, 15, 20, 15, 45, 649085)), '202505170232': ('F1-Score', 1.0, 1e-05, datetime.datetime(2025, 5, 17, 5, 26, 3, 436569)), '202505170910': ('Recall', 1.0, 1e-05, datetime.datetime(2025, 5, 17, 15, 36, 10, 805811)), '202505161903': ('AUC', 3.0, 1e-05, datetime.datetime(2025, 5, 17, 1, 21, 4, 994784)), '202505170526': ('F1-Score', 3.0, 1e-05, datetime.datetime(2025, 5, 17, 7, 32, 36, 458159)), '202505150921': ('Precision', 3.0, 1e-05, datetime.datetime(2025, 5, 15, 20, 44, 23, 491416)), '202505150606': ('Recall', 3.0, 1e-05, datetime.datetime(2025, 5, 16, 0, 37, 31, 384408)), '202505150349': ('AUC', 5.0, 1e-05, datetime.datetime(2025, 5, 16, 1, 29, 3, 290500)), '202505170732': ('F1-Score', 5.0, 1e-05, datetime.datetime(2025, 5, 17, 9, 10, 19, 355577)), '202505151015': ('Precision', 5.0, 1e-05, datetime.datetime(2025, 5, 15, 21, 3, 33, 654616)), '202505150652': ('Recall', 5.0, 1e-05, datetime.datetime(2025, 5, 16, 0, 33, 50, 439339))}\n",
      "Evaluating version 202505161637\n",
      "Metric: AUC, Epsilon: 1.0, Delta: 1e-05\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Evaluating version 202505070419\n",
      "Metric: Precision, Epsilon: 1.0, Delta: 1e-05\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Evaluating version 202505170232\n",
      "Metric: F1-Score, Epsilon: 1.0, Delta: 1e-05\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Evaluating version 202505170910\n",
      "Metric: Recall, Epsilon: 1.0, Delta: 1e-05\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Evaluating version 202505161903\n",
      "Metric: AUC, Epsilon: 3.0, Delta: 1e-05\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Evaluating version 202505170526\n",
      "Metric: F1-Score, Epsilon: 3.0, Delta: 1e-05\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Evaluating version 202505150921\n",
      "Metric: Precision, Epsilon: 3.0, Delta: 1e-05\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Evaluating version 202505150606\n",
      "Metric: Recall, Epsilon: 3.0, Delta: 1e-05\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Evaluating version 202505150349\n",
      "Metric: AUC, Epsilon: 5.0, Delta: 1e-05\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Evaluating version 202505170732\n",
      "Metric: F1-Score, Epsilon: 5.0, Delta: 1e-05\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Evaluating version 202505151015\n",
      "Metric: Precision, Epsilon: 5.0, Delta: 1e-05\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Evaluating version 202505150652\n",
      "Metric: Recall, Epsilon: 5.0, Delta: 1e-05\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# Set the working directory to the parent directory\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.dont_write_bytecode = True\n",
    "\n",
    "# Import relevant custom libraries\n",
    "from src.eda import data_info\n",
    "from src.evaluation import ValidationEvaluation\n",
    "\n",
    "# Import relevant libraries\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "# Config\n",
    "pd.set_option('display.max_columns', None) # Ensure all columns are displayed\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Read relevant files\n",
    "X_train = pd.read_feather(\"../data/processed/X_train.feather\")\n",
    "X_train_validate = pd.read_feather(\"../data/processed/X_train_validate.feather\")\n",
    "\n",
    "# Get data info\n",
    "var_info = data_info(X_train)\n",
    "all_cols = X_train.columns\n",
    "real_cols = var_info[var_info[\"var_type\"]==\"numerical\"][\"var_name\"].tolist()\n",
    "binary_cols = var_info[var_info[\"var_type\"]==\"binary\"][\"var_name\"].tolist()\n",
    "\n",
    "# Read relevant files\n",
    "X_validate = pd.read_feather(\"../data/processed/X_validate.feather\")\n",
    "y_validate = pd.read_feather(\"../data/processed/y_validate.feather\")\n",
    "\n",
    "# Initialize the validation evaluation\n",
    "valeval = ValidationEvaluation(X_validate, y_validate, real_cols, binary_cols, all_cols, dp_sgd=True)\n",
    "    \n",
    "# Read the log file\n",
    "log_path = \"../logs/dpsgd_tune_log.txt\"\n",
    "\n",
    "# Extract the latest successful Bayesian versions\n",
    "latest_successful_versions = valeval.extract_latest_successful_bayesian_versions(log_path)\n",
    "print(latest_successful_versions)\n",
    "\n",
    "# Evaluate the model performance\n",
    "eval_results = valeval.evaluate_model_performance(latest_successful_versions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dede3ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.468514516045322\n"
     ]
    }
   ],
   "source": [
    "from src.dp_utils_poisson import DPSGDSanitizer\n",
    "\n",
    "san = DPSGDSanitizer(len(X_train), 64, 3, 500, 1e-5)\n",
    "print(san.compute_noise_from_eps())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fba0727c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202505080154\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "202505080250\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "202505112013\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "202505080012\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import os\n",
    "os.chdir(\"/Users/trinhha/Documents/VU AMSTERDAM/STUDY/Thesis/Code/\")\n",
    "from src.models import AnomalyDetector\n",
    "\n",
    "X_test = pd.read_feather(\"data/processed/X_test.feather\")\n",
    "\n",
    "for version in eval_results.index.tolist():\n",
    "    print(version)\n",
    "    # Load model and hyperparameters\n",
    "    model = tf.keras.models.load_model(f\"models/baseline/{version}\")\n",
    "    with open(f\"hyperparams/baseline/{version}.pkl\", \"rb\") as f:\n",
    "        params = pickle.load(f)\n",
    "    detector = AnomalyDetector(\n",
    "                model=model,\n",
    "                real_cols=real_cols,\n",
    "                binary_cols=binary_cols,\n",
    "                all_cols=all_cols,\n",
    "                lam=params[\"lam\"],\n",
    "                gamma=params[\"gamma\"],\n",
    "            )\n",
    "    # Compute scores\n",
    "    scores, x_hat = detector._compute_anomaly_scores(X_test, test_set=True)\n",
    "\n",
    "    # Save reconstructed data\n",
    "    pd.DataFrame(x_hat, columns=all_cols).to_feather(f\"experiments/predictions/baseline/{version}_recons.feather\")\n",
    "\n",
    "    # Detect\n",
    "    y_pred = detector._detect(scores, params['threshold'])\n",
    "\n",
    "    # Save predictions\n",
    "    pd.DataFrame(y_pred, columns=[\"anomaly\"]).to_feather(f\"experiments/predictions/baseline/{version}_pred.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e4e8fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"../hyperparams/dpsgd/202506070611.pkl\", \"rb\") as f:\n",
    "    params = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a7344e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "params['threshold'] = 0.06004473716020584\n",
    "params['q'] = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b913b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../hyperparams/dpsgd/202506070611.pkl\", \"wb\") as f:\n",
    "    pickle.dump(params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a95599e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.dont_write_bytecode = True\n",
    "\n",
    "# Import relevant custom libraries\n",
    "from src.eda import data_info\n",
    "from src.evaluation import AnomalyDetector\n",
    "\n",
    "import os\n",
    "os.chdir(\"/Users/trinhha/Documents/VU AMSTERDAM/STUDY/Thesis/Code/\")\n",
    "\n",
    "X_test = pd.read_feather(\"data/processed/X_test.feather\")\n",
    "y_test = pd.read_feather(\"data/processed/y_test.feather\")\n",
    "# Get data info\n",
    "var_info = data_info(X_test)\n",
    "all_cols = X_test.columns\n",
    "real_cols = var_info[var_info[\"var_type\"]==\"numerical\"][\"var_name\"].tolist()\n",
    "binary_cols = var_info[var_info[\"var_type\"]==\"binary\"][\"var_name\"].tolist()\n",
    "\n",
    "with open(\"hyperparams/dpsgd/202506070611.pkl\", \"rb\") as f:\n",
    "    params = pickle.load(f)\n",
    "model = tf.keras.models.load_model(f\"models/dpsgd/202506070611\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfc3e32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = AnomalyDetector(\n",
    "                model=model,\n",
    "                real_cols=real_cols,\n",
    "                binary_cols=binary_cols,\n",
    "                all_cols=all_cols,\n",
    "                lam=params[\"lam\"],\n",
    "                gamma=params[\"gamma\"],\n",
    "                target_epsilon=3, delta=1e-5\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "347700b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = detector._compute_anomaly_scores(X_test)\n",
    "y_pred = detector._detect(scores, params[\"threshold\"])\n",
    "perf = detector._evaluate(y_pred, y_test, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8f9c720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7446102819237148,\n",
       " 'precision': 0.41311379006174653,\n",
       " 'recall': 0.6017130620985011,\n",
       " 'f1_score': 0.4898884239888424,\n",
       " 'auc': 0.7593880854671883}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7f3468",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
